{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "import torchtext\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import torch.optim as optim\n",
    "\n",
    "from kg.ner.model import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_df = pd.read_csv('/Users/tmorrill002/Documents/datasets/conll/transformed/train.csv')\n",
    "val_df = pd.read_csv('/Users/tmorrill002/Documents/datasets/conll/transformed/validation.csv')\n",
    "test_df = pd.read_csv('/Users/tmorrill002/Documents/datasets/conll/transformed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vocabulary and label dictionaries\n",
    "vocab = torchtext.vocab.Vocab(Counter(train_df['Token'].value_counts().to_dict()))\n",
    "label_dict = {}\n",
    "i = 0\n",
    "for k in train_df['NER_Tag_Normalized'].unique():\n",
    "    label_dict[k] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoNLL2003Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, vocab, label_dict, transform=None):\n",
    "        self.df = df\n",
    "        self.vocab = vocab\n",
    "        self.label_dict = label_dict\n",
    "        self.transform = transform\n",
    "        self.sentences, self.labels = self._prepare_data()\n",
    "    \n",
    "    def _prepare_data(self):\n",
    "        temp_df = self.df.groupby(['Article_ID', 'Sentence_ID'], as_index=False).agg(Sentence=('Token', list), Labels=('NER_Tag_Normalized', list))\n",
    "        sentences = temp_df['Sentence'].values.tolist()\n",
    "        labels = temp_df['Labels'].values.tolist()\n",
    "        return sentences, labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        indices = []\n",
    "        for token in self.sentences[idx]:\n",
    "            indices.append(self.vocab[token])\n",
    "        labels = []\n",
    "        for label in self.labels[idx]:\n",
    "            labels.append(self.label_dict[label])\n",
    "        \n",
    "        return torch.tensor(indices), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CoNLL2003Dataset(train_df, vocab, label_dict)\n",
    "val_dataset = CoNLL2003Dataset(val_df, vocab, label_dict)\n",
    "test_dataset = CoNLL2003Dataset(test_df, vocab, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert vocab[train_df.iloc[0]['Token']] == train_dataset[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert label_dict[train_df.iloc[0]['NER_Tag_Normalized']] == train_dataset[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-19a9c619550e>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  small_batch.append(torch.tensor(train_dataset[0][0]))\n",
      "<ipython-input-8-19a9c619550e>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  small_batch.append(torch.tensor(train_dataset[1][0]))\n",
      "<ipython-input-8-19a9c619550e>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  small_labels_batch.append(torch.tensor(train_dataset[0][1]))\n",
      "<ipython-input-8-19a9c619550e>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  small_labels_batch.append(torch.tensor(train_dataset[1][1]))\n"
     ]
    }
   ],
   "source": [
    "small_batch = []\n",
    "small_batch.append(torch.tensor(train_dataset[0][0]))\n",
    "small_batch.append(torch.tensor(train_dataset[1][0]))\n",
    "small_batch_lens = [len(x) for x in small_batch]\n",
    "\n",
    "small_labels_batch = []\n",
    "small_labels_batch.append(torch.tensor(train_dataset[0][1]))\n",
    "small_labels_batch.append(torch.tensor(train_dataset[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_batch_padded = pad_sequence(small_batch, batch_first=True, padding_value=vocab['<pad>'])\n",
    "small_labels_batch_padded = pad_sequence(small_labels_batch, batch_first=True, padding_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  964, 22406,   236,   771,     7,  4586,   210,  7683,     2],\n",
       "        [  737,  2088,     1,     1,     1,     1,     1,     1,     1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_batch_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  1,  1,  1,  2,  1,  1],\n",
       "        [ 3,  3, -1, -1, -1, -1, -1, -1, -1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_labels_batch_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 2]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_batch_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed = pack_padded_sequence(small_batch_padded, small_batch_lens, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([  964,   737, 22406,  2088,   236,   771,     7,  4586,   210,  7683,\n",
       "            2]), batch_sizes=tensor([2, 2, 1, 1, 1, 1, 1, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, sequence_lengths = pad_packed_sequence(packed, batch_first=True, padding_value=vocab['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'vocab_size': len(vocab),\n",
    "    'embedding_dim': 128,\n",
    "    'hidden_size': 128,\n",
    "    'num_classes': len(label_dict),\n",
    "    'batch_size': 16\n",
    "}\n",
    "config = SimpleNamespace(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model((small_batch_padded, small_batch_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, labels):\n",
    "    labels = labels.reshape(-1)\n",
    "    mask = (labels >= 0).float()\n",
    "    labels = labels % outputs.shape[1]\n",
    "    num_tokens = mask.sum()\n",
    "    return -torch.sum(outputs[range(outputs.shape[0]), labels] * mask) / num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6675, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(output, small_labels_batch_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    sentence_indices, sentence_labels = zip(*batch)\n",
    "    sentence_lens = [len(x) for x in sentence_indices]\n",
    "    \n",
    "    # vocab['<pad>'] = 1\n",
    "    sentences_padded = pad_sequence(sentence_indices, batch_first=True, padding_value=1)\n",
    "    labels_padded = pad_sequence(sentence_labels, batch_first=True, padding_value=-1)\n",
    "    \n",
    "    return (sentences_padded, sentence_lens), labels_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, collate_fn=collate_fn, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=16, collate_fn=collate_fn)\n",
    "test_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=16, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(output, lengths, concatenate=True):\n",
    "    # extract predictions\n",
    "    max_len = max(lengths)\n",
    "    preds = output.argmax(dim=1)\n",
    "    i = 0\n",
    "    preds_list = []\n",
    "    for length in lengths:\n",
    "        start = i*max_len\n",
    "        stop = start + length\n",
    "        preds_list.append(preds[start:stop])\n",
    "        i += 1\n",
    "    if concatenate:\n",
    "        return torch.cat(preds_list)\n",
    "    return preds_list\n",
    "\n",
    "def recover_labels(padded_labels, lengths):\n",
    "    # extract labels\n",
    "    max_len = max(lengths)\n",
    "    labels_vector = padded_labels.reshape(-1)\n",
    "    i = 0\n",
    "    labels_list = []\n",
    "    for length in lengths:\n",
    "        start = i*max_len\n",
    "        stop = start + length\n",
    "        labels_list.append(labels_vector[start:stop])\n",
    "        i += 1\n",
    "    return torch.cat(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(output, sentences, labels, dataset='Train'):\n",
    "    batch_preds = get_predictions(output, sentences[1])\n",
    "    batch_labels = recover_labels(labels, sentences[1])\n",
    "    raw_acc = accuracy_score(batch_preds, batch_labels)\n",
    "    acc = round(raw_acc * 100, 2)\n",
    "    # print(f'{dataset} accuracy score: {acc}%')\n",
    "    return raw_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1\n",
      "Sample train batch - loss value: 1.6553 \t accuracy score: 9.0%\n",
      "Sample train batch - loss value: 0.4608 \t accuracy score: 87.56%\n",
      "Sample train batch - loss value: 0.5534 \t accuracy score: 81.68%\n",
      "Sample train batch - loss value: 0.4797 \t accuracy score: 82.86%\n",
      "Sample train batch - loss value: 0.3715 \t accuracy score: 88.36%\n",
      "Sample train batch - loss value: 0.3635 \t accuracy score: 88.13%\n",
      "Sample train batch - loss value: 0.414 \t accuracy score: 86.39%\n",
      "Sample train batch - loss value: 0.2435 \t accuracy score: 91.28%\n",
      "Sample train batch - loss value: 0.2907 \t accuracy score: 93.02%\n",
      "Average validation loss: 0.3233\n",
      "Validation accuracy score: 90.07%\n",
      "\n",
      "Epoch number: 2\n",
      "Sample train batch - loss value: 0.2388 \t accuracy score: 91.75%\n",
      "Sample train batch - loss value: 0.3256 \t accuracy score: 88.61%\n",
      "Sample train batch - loss value: 0.2279 \t accuracy score: 92.89%\n",
      "Sample train batch - loss value: 0.2019 \t accuracy score: 94.88%\n",
      "Sample train batch - loss value: 0.2107 \t accuracy score: 94.89%\n",
      "Sample train batch - loss value: 0.2971 \t accuracy score: 90.57%\n",
      "Sample train batch - loss value: 0.1252 \t accuracy score: 96.25%\n",
      "Sample train batch - loss value: 0.1377 \t accuracy score: 95.59%\n",
      "Sample train batch - loss value: 0.1486 \t accuracy score: 96.41%\n",
      "Average validation loss: 0.2414\n",
      "Validation accuracy score: 93.16%\n",
      "\n",
      "Epoch number: 3\n",
      "Sample train batch - loss value: 0.0847 \t accuracy score: 98.09%\n",
      "Sample train batch - loss value: 0.1135 \t accuracy score: 96.93%\n",
      "Sample train batch - loss value: 0.06 \t accuracy score: 98.07%\n",
      "Sample train batch - loss value: 0.1711 \t accuracy score: 93.57%\n",
      "Sample train batch - loss value: 0.1264 \t accuracy score: 95.19%\n",
      "Sample train batch - loss value: 0.1183 \t accuracy score: 96.1%\n",
      "Sample train batch - loss value: 0.1309 \t accuracy score: 95.45%\n",
      "Sample train batch - loss value: 0.0611 \t accuracy score: 98.21%\n",
      "Sample train batch - loss value: 0.1156 \t accuracy score: 96.51%\n",
      "Average validation loss: 0.2093\n",
      "Validation accuracy score: 94.18%\n",
      "\n",
      "Epoch number: 4\n",
      "Sample train batch - loss value: 0.0511 \t accuracy score: 98.85%\n",
      "Sample train batch - loss value: 0.0492 \t accuracy score: 98.81%\n",
      "Sample train batch - loss value: 0.0393 \t accuracy score: 98.58%\n",
      "Sample train batch - loss value: 0.0401 \t accuracy score: 100.0%\n",
      "Sample train batch - loss value: 0.0509 \t accuracy score: 98.01%\n",
      "Sample train batch - loss value: 0.0948 \t accuracy score: 98.19%\n",
      "Sample train batch - loss value: 0.0707 \t accuracy score: 98.51%\n",
      "Sample train batch - loss value: 0.0269 \t accuracy score: 99.49%\n",
      "Sample train batch - loss value: 0.0406 \t accuracy score: 98.93%\n",
      "Average validation loss: 0.2398\n",
      "Validation accuracy score: 94.21%\n",
      "\n",
      "Epoch number: 5\n",
      "Sample train batch - loss value: 0.0211 \t accuracy score: 99.35%\n",
      "Sample train batch - loss value: 0.0248 \t accuracy score: 99.61%\n",
      "Sample train batch - loss value: 0.0374 \t accuracy score: 98.86%\n",
      "Sample train batch - loss value: 0.0278 \t accuracy score: 99.01%\n",
      "Sample train batch - loss value: 0.0202 \t accuracy score: 99.67%\n",
      "Sample train batch - loss value: 0.0295 \t accuracy score: 99.16%\n",
      "Sample train batch - loss value: 0.0281 \t accuracy score: 99.18%\n",
      "Sample train batch - loss value: 0.0514 \t accuracy score: 98.95%\n",
      "Sample train batch - loss value: 0.0314 \t accuracy score: 98.66%\n",
      "Average validation loss: 0.2697\n",
      "Validation accuracy score: 94.55%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATIENCE=3\n",
    "running_patience = PATIENCE\n",
    "best_val_loss = np.inf\n",
    "record_loss = []\n",
    "for i in range(5):\n",
    "    model.train()\n",
    "    print(f'Epoch number: {i+1}')\n",
    "    j = 0\n",
    "    for sentences, labels in train_dataloader:\n",
    "        output = model(sentences)\n",
    "        loss = loss_fn(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if j % 100 == 0:\n",
    "            record_loss.append(loss)\n",
    "            print(f'Sample train batch - loss value: {round(loss.item(), 4)} \\t accuracy score: {round(metrics(output, sentences, labels)*100, 2)}%')\n",
    "        j += 1\n",
    "    \n",
    "    # monitor validation loss\n",
    "    model.eval()\n",
    "    val_loss_scores = []\n",
    "    val_acc_scores = []\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    for sentences, labels in val_dataloader:\n",
    "        output = model(sentences)\n",
    "        loss = loss_fn(output, labels)\n",
    "        val_loss_scores.append(loss.item())\n",
    "        val_acc_scores.append(metrics(output, sentences, labels))\n",
    "        val_preds += get_predictions(output, sentences[1]).tolist()\n",
    "        val_labels += recover_labels(labels, sentences[1]).tolist()\n",
    "    val_loss = round(np.mean(val_loss_scores), 4)\n",
    "    val_acc = round(np.mean(val_acc_scores)*100, 2)\n",
    "    print(f'Average validation loss: {val_loss}')\n",
    "    print(f'Validation accuracy score: {val_acc}%')\n",
    "    \n",
    "    # stopping criterion\n",
    "    if val_loss < best_val_loss:\n",
    "        running_patience = PATIENCE\n",
    "        best_val_loss = val_loss\n",
    "    else:\n",
    "        running_patience -= 1\n",
    "        if running_patience == 0:\n",
    "            print(f'Model has not improved for {PATIENCE} epochs. Stopping training.')\n",
    "            break\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = list(set(val_preds).union(set(val_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ORG       0.85      0.65      0.74      2092\n",
      "           O       0.95      0.99      0.97     42759\n",
      "        MISC       0.86      0.73      0.79      1268\n",
      "         PER       0.93      0.66      0.77      3149\n",
      "         LOC       0.87      0.78      0.83      2094\n",
      "\n",
      "    accuracy                           0.94     51362\n",
      "   macro avg       0.89      0.76      0.82     51362\n",
      "weighted avg       0.94      0.94      0.94     51362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_labels, val_preds, labels=label_set, target_names=list(label_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python - Knowledge Graphs",
   "language": "python",
   "name": "knowledge-graphs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
