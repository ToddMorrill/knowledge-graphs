{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tmorrill002/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/tmorrill002/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     /Users/tmorrill002/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import conll2000\n",
    "\n",
    "import kg.ner.utils as utils\n",
    "from kg.ner.unsupervised import NounPhraseDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '/Users/tmorrill002/Documents/datasets/conll/transformed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = utils.load_train_data(data_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What fraction of NER tags are Noun Phrases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_dict['train.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns_over_NER(df, noun_col = 'Chunk_Tag', ner_col = 'NER_Tag_Normalized'):\n",
    "    ner_df = df[df[ner_col] != 'O']\n",
    "    noun_phrase_token_count = len(ner_df[(ner_df[noun_col] == 'I-NP') | (ner_df[noun_col] == 'B-NP')])\n",
    "    print(f'Count of noun phrase tokens among NER tokens: {noun_phrase_token_count}')\n",
    "    print(f'Count of NER tokens: {len(ner_df)}')\n",
    "    print(f'Percent of NER tokens that are part of noun phrases: {round(noun_phrase_token_count / len(ner_df),4) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of noun phrase tokens among NER tokens: 33054\n",
      "Count of NER tokens: 34043\n",
      "Percent of NER tokens that are part of noun phrases: 97.09%\n"
     ]
    }
   ],
   "source": [
    "nouns_over_NER(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What fraction of Noun Phrase tokens are NER tagged?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NER_over_nouns(df, noun_col = 'Chunk_Tag', ner_col = 'NER_Tag_Normalized'):\n",
    "    noun_phrase_df = df[(df[noun_col] == 'I-NP') | (df[noun_col] == 'B-NP')]\n",
    "    ner_tag_token_count = len(noun_phrase_df[noun_phrase_df[ner_col] != 'O'])\n",
    "    print(f'Count of NER tokens among noun phrase tokens: {ner_tag_token_count}')\n",
    "    print(f'Count of noun phrase tokens: {len(noun_phrase_df)}')\n",
    "    print(f'Percent of noun phrase tokens that are part of NER tags: {round(ner_tag_token_count / len(noun_phrase_df), 4) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of NER tokens among noun phrase tokens: 33054\n",
      "Count of noun phrase tokens: 124032\n",
      "Percent of noun phrase tokens that are part of NER tags: 26.650000000000002%\n"
     ]
    }
   ],
   "source": [
    "NER_over_nouns(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "1. NER Tags are almost exclusively noun phrases (97%) -> noun phrase candidates will yield high recall\n",
    "2. Noun phrases encompass a lot more than NER tags -> noun phrase candidates will yield low precision and other techniques should be used to reduce the number of false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Unsupervised Noun Phrase Detection Against CoNLL-2000 and CoNLL-2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conll_2000_test_sentences = conll2000.chunked_sents('test.txt', chunk_types=['NP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_parser = NounPhraseDetection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  87.7%%\n",
      "    Precision:     70.6%%\n",
      "    Recall:        67.8%%\n",
      "    F-Measure:     69.2%%\n"
     ]
    }
   ],
   "source": [
    "print(chunk_parser.evaluate(conll_2000_test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate(x):\n",
    "    return (x['Token'], x['POS_Tag'], x['Chunk_Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Tags'] = train_df.apply(consolidate, axis=1) #passes a Series object, row-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth labeled data containing (token, pos, chunk), used for evaluation\n",
    "train_conll_2003 = train_df.groupby(['Article_ID', 'Sentence_ID'], )['Tags'].apply(list).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos tagged sentences only containing (token, pos), used to make predictions\n",
    "train_conll_2003_pos_tags = []\n",
    "for sentence in train_conll_2003:\n",
    "    temp_sentence = []\n",
    "    for token, pos, chunk in sentence:\n",
    "        temp_sentence.append((token, pos))\n",
    "    train_conll_2003_pos_tags.append(temp_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples must be in \"tree\" format to use evaluation code\n",
    "trees = []\n",
    "for example in train_conll_2003:\n",
    "    trees.append(nltk.chunk.conlltags2tree(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  67.4%%\n",
      "    Precision:     80.5%%\n",
      "    Recall:        43.7%%\n",
      "    F-Measure:     56.7%%\n"
     ]
    }
   ],
   "source": [
    "# getting harmed here because B-NP tags aren't marked appropriately in CoNLL-2003\n",
    "print(chunk_parser.evaluate(trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_trees = []\n",
    "for example in train_conll_2003_pos_tags:\n",
    "    prediction_trees.append(chunk_parser.parse(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for sentence in prediction_trees:\n",
    "    predictions.append(nltk.chunk.tree2conlltags(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = [prediction for sentence in predictions for prediction in sentence ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Prediction'] = flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Prediction'] = train_df['Prediction'].apply(lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Noun_Phrase'] = train_df['Prediction'] != 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of noun phrase tokens among NER tokens: 33030\n",
      "Count of NER tokens: 34043\n",
      "Percent of NER tokens that are part of noun phrases: 97.02%\n"
     ]
    }
   ],
   "source": [
    "nouns_over_NER(train_df, 'Prediction', 'NER_Tag_Normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of NER tokens among noun phrase tokens: 33030\n",
      "Count of noun phrase tokens: 124428\n",
      "Percent of noun phrase tokens that are part of NER tags: 26.55%\n"
     ]
    }
   ],
   "source": [
    "NER_over_nouns(train_df, 'Prediction', 'NER_Tag_Normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['NP_Chunk_Tag'] = (train_df['Chunk_Tag'] == 'I-NP') | (train_df['Chunk_Tag'] == 'B-NP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9570476522559068"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agreement between existing ConLL-2003 noun phrase tags and the predicted tags\n",
    "(train_df['Noun_Phrase'] == train_df['NP_Chunk_Tag']).sum() / len(train_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python - Knowledge Graphs",
   "language": "python",
   "name": "knowledge-graphs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
