{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     self signed certificate in certificate chain\n",
      "[nltk_data]     (_ssl.c:1125)>\n",
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify\n",
      "[nltk_data]     failed: self signed certificate in certificate chain\n",
      "[nltk_data]     (_ssl.c:1125)>\n",
      "[nltk_data] Error loading conll2000: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     self signed certificate in certificate chain\n",
      "[nltk_data]     (_ssl.c:1125)>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     self signed certificate in certificate chain\n",
      "[nltk_data]     (_ssl.c:1125)>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import conll2000\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import kg.ner.utils as utils\n",
    "from kg.ner.unsupervised import NounPhraseDetection, TFIDFScore, TextRankScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '/Users/tmorrill002/Documents/datasets/conll/transformed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = utils.load_train_data(data_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What fraction of NER tags are Noun Phrases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_dict['train.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns_over_NER(df, noun_col = 'Chunk_Tag', ner_col = 'NER_Tag_Normalized'):\n",
    "    ner_df = df[df[ner_col] != 'O']\n",
    "    noun_phrase_token_count = len(ner_df[(ner_df[noun_col] == 'I-NP') | (ner_df[noun_col] == 'B-NP')])\n",
    "    print(f'Count of noun phrase tokens among NER tokens: {noun_phrase_token_count}')\n",
    "    print(f'Count of NER tokens: {len(ner_df)}')\n",
    "    print(f'Percent of NER tokens that are part of noun phrases: {round(noun_phrase_token_count / len(ner_df),4) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of noun phrase tokens among NER tokens: 33054\n",
      "Count of NER tokens: 34043\n",
      "Percent of NER tokens that are part of noun phrases: 97.09%\n"
     ]
    }
   ],
   "source": [
    "nouns_over_NER(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What fraction of Noun Phrase tokens are NER tagged?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NER_over_nouns(df, noun_col = 'Chunk_Tag', ner_col = 'NER_Tag_Normalized'):\n",
    "    noun_phrase_df = df[(df[noun_col] == 'I-NP') | (df[noun_col] == 'B-NP')]\n",
    "    ner_tag_token_count = len(noun_phrase_df[noun_phrase_df[ner_col] != 'O'])\n",
    "    print(f'Count of NER tokens among noun phrase tokens: {ner_tag_token_count}')\n",
    "    print(f'Count of noun phrase tokens: {len(noun_phrase_df)}')\n",
    "    print(f'Percent of noun phrase tokens that are part of NER tags: {round(ner_tag_token_count / len(noun_phrase_df), 4) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of NER tokens among noun phrase tokens: 33054\n",
      "Count of noun phrase tokens: 124032\n",
      "Percent of noun phrase tokens that are part of NER tags: 26.650000000000002%\n"
     ]
    }
   ],
   "source": [
    "NER_over_nouns(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "1. NER Tags are almost exclusively noun phrases (97%) -> noun phrase candidates will yield high recall\n",
    "2. Noun phrases encompass a lot more than NER tags -> noun phrase candidates will yield low precision and other techniques should be used to reduce the number of false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Unsupervised Noun Phrase Detection Against CoNLL-2000 and CoNLL-2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conll_2000_test_sentences = conll2000.chunked_sents('test.txt', chunk_types=['NP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_parser = NounPhraseDetection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  87.7%%\n",
      "    Precision:     70.6%%\n",
      "    Recall:        67.8%%\n",
      "    F-Measure:     69.2%%\n"
     ]
    }
   ],
   "source": [
    "print(chunk_parser.evaluate(conll_2000_test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate(x):\n",
    "    return (x['Token'], x['POS_Tag'], x['Chunk_Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Tags'] = train_df.apply(consolidate, axis=1) #passes a Series object, row-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth labeled data containing (token, pos, chunk), used for evaluation\n",
    "train_conll_2003 = train_df.groupby(['Article_ID', 'Sentence_ID'], )['Tags'].apply(list).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos tagged sentences only containing (token, pos), used to make predictions\n",
    "train_conll_2003_pos_tags = []\n",
    "for sentence in train_conll_2003:\n",
    "    temp_sentence = []\n",
    "    for token, pos, chunk in sentence:\n",
    "        temp_sentence.append((token, pos))\n",
    "    train_conll_2003_pos_tags.append(temp_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples must be in \"tree\" format to use evaluation code\n",
    "trees = []\n",
    "for example in train_conll_2003:\n",
    "    trees.append(nltk.chunk.conlltags2tree(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  67.4%%\n",
      "    Precision:     80.5%%\n",
      "    Recall:        43.7%%\n",
      "    F-Measure:     56.7%%\n"
     ]
    }
   ],
   "source": [
    "# getting harmed here because B-NP tags aren't marked appropriately in CoNLL-2003\n",
    "print(chunk_parser.evaluate(trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_trees = []\n",
    "for example in train_conll_2003_pos_tags:\n",
    "    prediction_trees.append(chunk_parser.parse(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for sentence in prediction_trees:\n",
    "    predictions.append(nltk.chunk.tree2conlltags(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = [prediction for sentence in predictions for prediction in sentence ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Prediction'] = flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Prediction'] = train_df['Prediction'].apply(lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Noun_Phrase'] = train_df['Prediction'] != 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of noun phrase tokens among NER tokens: 33030\n",
      "Count of NER tokens: 34043\n",
      "Percent of NER tokens that are part of noun phrases: 97.02%\n"
     ]
    }
   ],
   "source": [
    "nouns_over_NER(train_df, 'Prediction', 'NER_Tag_Normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of NER tokens among noun phrase tokens: 33030\n",
      "Count of noun phrase tokens: 124428\n",
      "Percent of noun phrase tokens that are part of NER tags: 26.55%\n"
     ]
    }
   ],
   "source": [
    "NER_over_nouns(train_df, 'Prediction', 'NER_Tag_Normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['NP_Chunk_Tag'] = (train_df['Chunk_Tag'] == 'I-NP') | (train_df['Chunk_Tag'] == 'B-NP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9570476522559068"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agreement between existing ConLL-2003 noun phrase tags and the predicted tags\n",
    "(train_df['Noun_Phrase'] == train_df['NP_Chunk_Tag']).sum() / len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate TF-IDF Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_extractor = TFIDFScore(chunk_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['NER_Tag_Flag'] = train_df['NER_Tag'] != 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather up articles\n",
    "articles = train_df.groupby(['Article_ID'], )['Token'].apply(lambda x: ' '.join([str(y) for y in list(x)])).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit TFIDF model\n",
    "entity_extractor.fit(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get candidate phrases\n",
    "candidates = []\n",
    "for article in articles:\n",
    "    # manually tokenize because nltk tokenizer is converting 'C$' -> ['C', '$'] and throwing off comparison\n",
    "    sentences = utils.tokenize_text(article)\n",
    "    article = [sentence.split() for sentence in sentences]\n",
    "    article = utils.tag_pos(article)\n",
    "    for candidate in entity_extractor.candidates(article, preprocess = False):\n",
    "        candidates.append(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tmorrill002/Documents/knowledge-graphs/kg/ner/unsupervised.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  scores = sums / token_counts\n"
     ]
    }
   ],
   "source": [
    "scores = entity_extractor.score_phrases(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_scored_phrases(scored_candidates):\n",
    "    df = pd.DataFrame(scored_candidates, columns=['Predicted_Phrase', 'Noun_Phrase_Flag', 'Score'])\n",
    "    df['Phrase_ID'] = df.index\n",
    "    df['Predicted_Phrase'] = df['Predicted_Phrase'].apply(lambda x: x.split())\n",
    "    df = df.explode('Predicted_Phrase')\n",
    "    # punctuation isn't getting assigned a score, fill with zero for now\n",
    "    df['Score'] = df['Score'].fillna(0.0)\n",
    "    # TODO: Investigate why this is happening\n",
    "    df['Predicted_Phrase'] = df['Predicted_Phrase'].replace('``', '\"')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = prepare_scored_phrases(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dfs(train_df, prediction_df):\n",
    "    \n",
    "    assert len(train_df) == len(prediction_df)\n",
    "    eval_df = pd.concat((train_df, prediction_df.reset_index(drop=True)), axis=1)\n",
    "\n",
    "    # TODO: why are some CoNLL-2003 tokens NaN?\n",
    "    eval_df = eval_df.dropna(subset=['Token'])\n",
    "    assert (eval_df['Token'] == eval_df['Predicted_Phrase']).sum() == len(eval_df) \n",
    "    \n",
    "    eval_df['Predicted_Entity_Flag'] = eval_df['Noun_Phrase_Flag']\n",
    "    \n",
    "    return eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_eval_df = merge_dfs(train_df, prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_threshold(eval_df, scoring_method='TFIDF', optimization_steps=32):\n",
    "    # optimize threshold to maximize macro f1\n",
    "    start = eval_df['Score'].describe()['25%']\n",
    "    stop = eval_df['Score'].describe()['75%']\n",
    "    step = (stop - start) / optimization_steps\n",
    "    \n",
    "    predictions = []\n",
    "    for thresh in np.arange(start, stop, step=step):\n",
    "        predictions.append((thresh, (eval_df['Noun_Phrase_Flag'] & (eval_df['Score'] >= thresh)).values))\n",
    "\n",
    "    macro_f1_scores = []\n",
    "    for prediction in predictions:\n",
    "        report = classification_report(eval_df['NER_Tag_Flag'], prediction[1], output_dict=True)\n",
    "        macro_f1_scores.append((prediction[0], report['True']['f1-score']))\n",
    "\n",
    "    optimized_threshold = max(macro_f1_scores, key=lambda x: x[1])[0]\n",
    "    \n",
    "    print(f'Optimize {scoring_method} threshold ({optimized_threshold}) to maximize positive class (Entity = True) F1 score.')\n",
    "    print(f'Range searched - start: {start}, stop: {stop}, step: {step}')\n",
    "    print(classification_report(eval_df['NER_Tag_Flag'], (eval_df['Noun_Phrase_Flag'] & (eval_df['Score'] >= optimized_threshold))))\n",
    "    \n",
    "    return optimized_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(eval_df, scoring_method='TFIDF', optimization_steps=32):\n",
    "    # baseline of just using noun phrases to identify entities (high recall, low precision)\n",
    "    print('Baseline using noun phrases to identify entities:')\n",
    "    print(classification_report(eval_df['NER_Tag_Flag'], eval_df['Predicted_Entity_Flag']))\n",
    "    print()\n",
    "    \n",
    "    # use score and a threshold\n",
    "    median_threshold = eval_df['Score'].describe()['50%']\n",
    "    eval_df[f'Predicted_Entity_Flag_{scoring_method}_Median'] = (eval_df['Noun_Phrase_Flag'] & (eval_df['Score'] > median_threshold))\n",
    "    print(f'Use the median {scoring_method} score ({round(median_threshold, 4)}) as a threshold to identify entities.')\n",
    "    print(classification_report(eval_df['NER_Tag_Flag'], eval_df[f'Predicted_Entity_Flag_{scoring_method}_Median']))\n",
    "    print()\n",
    "    \n",
    "    return optimize_threshold(eval_df, scoring_method, optimization_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline using noun phrases to identify entities:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.51      0.68    169575\n",
      "        True       0.29      0.98      0.44     34043\n",
      "\n",
      "    accuracy                           0.59    203618\n",
      "   macro avg       0.64      0.74      0.56    203618\n",
      "weighted avg       0.87      0.59      0.64    203618\n",
      "\n",
      "\n",
      "Use the median TFIDF score (3.8135) as a threshold to identify entities.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.69      0.80    169575\n",
      "        True       0.34      0.81      0.48     34043\n",
      "\n",
      "    accuracy                           0.71    203618\n",
      "   macro avg       0.64      0.75      0.64    203618\n",
      "weighted avg       0.85      0.71      0.74    203618\n",
      "\n",
      "\n",
      "Optimize TFIDF threshold (4.497740067462728) to maximize positive class (Entity = True) F1 score.\n",
      "Range searched - start: 2.694243793971549, stop: 4.913931515191463, step: 0.0693652412881223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.80      0.85    169575\n",
      "        True       0.39      0.64      0.48     34043\n",
      "\n",
      "    accuracy                           0.77    203618\n",
      "   macro avg       0.65      0.72      0.67    203618\n",
      "weighted avg       0.83      0.77      0.79    203618\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.497740067462728"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(tfidf_eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate TextRank Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_parser = NounPhraseDetection()\n",
    "scorer = TextRankScore(chunk_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather up articles\n",
    "articles = train_df.groupby(['Article_ID'], )['Token'].apply(lambda x: ' '.join([str(y) for y in list(x)])).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "# get candidate phrases\n",
    "candidates = []\n",
    "scored_candidates = []\n",
    "for idx, article in enumerate(articles):\n",
    "    # manually tokenize because nltk tokenizer is converting 'C$' -> ['C', '$'] and throwing off comparison\n",
    "    sentences = utils.tokenize_text(article)\n",
    "    article = [sentence.split() for sentence in sentences]\n",
    "    article = utils.tag_pos(article)\n",
    "    temp_candidates = []\n",
    "    for candidate in scorer.candidates(article, preprocess = False):\n",
    "        candidates.append(candidate)\n",
    "        temp_candidates.append(candidate)\n",
    "    candidate_noun_phrases = [tokens for tokens, flag in temp_candidates if flag]\n",
    "    scored_words = scorer.fit_document(candidate_noun_phrases)\n",
    "    for candidate in scorer.score_phrases(temp_candidates, scored_words):\n",
    "        scored_candidates.append(candidate)\n",
    "    if idx % 100 == 0:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scorer.fit(candidate_noun_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scored_candidates = scorer.score_phrases(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = [(token, flag, score) for token, flag, score in scored_candidates if flag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101152"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scored_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rank_df = prepare_scored_phrases(scored_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rank_eval_df = merge_dfs(train_df, text_rank_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article_ID</th>\n",
       "      <th>Sentence_ID</th>\n",
       "      <th>Token_ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>POS_Tag</th>\n",
       "      <th>Chunk_Tag</th>\n",
       "      <th>NER_Tag</th>\n",
       "      <th>NER_Tag_ID</th>\n",
       "      <th>NER_Tag_Normalized</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Noun_Phrase</th>\n",
       "      <th>NP_Chunk_Tag</th>\n",
       "      <th>NER_Tag_Flag</th>\n",
       "      <th>Predicted_Phrase</th>\n",
       "      <th>Noun_Phrase_Flag</th>\n",
       "      <th>Score</th>\n",
       "      <th>Phrase_ID</th>\n",
       "      <th>Predicted_Entity_Flag</th>\n",
       "      <th>Predicted_Entity_Flag_TextRank_Median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EU</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ORG</td>\n",
       "      <td>(EU, NNP, I-NP)</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>EU</td>\n",
       "      <td>True</td>\n",
       "      <td>0.015790</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rejects</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(rejects, VBZ, I-VP)</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rejects</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>German</td>\n",
       "      <td>JJ</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MISC</td>\n",
       "      <td>(German, JJ, I-NP)</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>German</td>\n",
       "      <td>True</td>\n",
       "      <td>0.006349</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>call</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(call, NN, I-NP)</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>call</td>\n",
       "      <td>True</td>\n",
       "      <td>0.006349</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(to, TO, I-VP)</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>to</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203616</th>\n",
       "      <td>945</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>three</td>\n",
       "      <td>CD</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(three, CD, I-NP)</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>three</td>\n",
       "      <td>True</td>\n",
       "      <td>0.059998</td>\n",
       "      <td>101151</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203617</th>\n",
       "      <td>945</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>23497.0</td>\n",
       "      <td>ORG</td>\n",
       "      <td>(Swansea, NN, I-NP)</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>True</td>\n",
       "      <td>0.059998</td>\n",
       "      <td>101151</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203618</th>\n",
       "      <td>945</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CD</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(1, CD, I-NP)</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.059998</td>\n",
       "      <td>101151</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203619</th>\n",
       "      <td>945</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>23498.0</td>\n",
       "      <td>ORG</td>\n",
       "      <td>(Lincoln, NNP, I-NP)</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>True</td>\n",
       "      <td>0.059998</td>\n",
       "      <td>101151</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203620</th>\n",
       "      <td>945</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>CD</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(2, CD, I-NP)</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.059998</td>\n",
       "      <td>101151</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203618 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Article_ID  Sentence_ID  Token_ID    Token POS_Tag Chunk_Tag NER_Tag  \\\n",
       "0                0            0         0       EU     NNP      I-NP   I-ORG   \n",
       "1                0            0         1  rejects     VBZ      I-VP       O   \n",
       "2                0            0         2   German      JJ      I-NP  I-MISC   \n",
       "3                0            0         3     call      NN      I-NP       O   \n",
       "4                0            0         4       to      TO      I-VP       O   \n",
       "...            ...          ...       ...      ...     ...       ...     ...   \n",
       "203616         945            6         1    three      CD      I-NP       O   \n",
       "203617         945            7         0  Swansea      NN      I-NP   I-ORG   \n",
       "203618         945            7         1        1      CD      I-NP       O   \n",
       "203619         945            7         2  Lincoln     NNP      I-NP   I-ORG   \n",
       "203620         945            7         3        2      CD      I-NP       O   \n",
       "\n",
       "        NER_Tag_ID NER_Tag_Normalized                  Tags Prediction  \\\n",
       "0              0.0                ORG       (EU, NNP, I-NP)       B-NP   \n",
       "1              NaN                  O  (rejects, VBZ, I-VP)          O   \n",
       "2              1.0               MISC    (German, JJ, I-NP)       B-NP   \n",
       "3              NaN                  O      (call, NN, I-NP)       I-NP   \n",
       "4              NaN                  O        (to, TO, I-VP)          O   \n",
       "...            ...                ...                   ...        ...   \n",
       "203616         NaN                  O     (three, CD, I-NP)       I-NP   \n",
       "203617     23497.0                ORG   (Swansea, NN, I-NP)       B-NP   \n",
       "203618         NaN                  O         (1, CD, I-NP)       I-NP   \n",
       "203619     23498.0                ORG  (Lincoln, NNP, I-NP)       I-NP   \n",
       "203620         NaN                  O         (2, CD, I-NP)       I-NP   \n",
       "\n",
       "        Noun_Phrase  NP_Chunk_Tag  NER_Tag_Flag Predicted_Phrase  \\\n",
       "0              True          True          True               EU   \n",
       "1             False         False         False          rejects   \n",
       "2              True          True          True           German   \n",
       "3              True          True         False             call   \n",
       "4             False         False         False               to   \n",
       "...             ...           ...           ...              ...   \n",
       "203616         True          True         False            three   \n",
       "203617         True          True          True          Swansea   \n",
       "203618         True          True         False                1   \n",
       "203619         True          True          True          Lincoln   \n",
       "203620         True          True         False                2   \n",
       "\n",
       "        Noun_Phrase_Flag     Score  Phrase_ID  Predicted_Entity_Flag  \\\n",
       "0                   True  0.015790          0                   True   \n",
       "1                  False  0.000000          1                  False   \n",
       "2                   True  0.006349          2                   True   \n",
       "3                   True  0.006349          2                   True   \n",
       "4                  False  0.000000          3                  False   \n",
       "...                  ...       ...        ...                    ...   \n",
       "203616              True  0.059998     101151                   True   \n",
       "203617              True  0.059998     101151                   True   \n",
       "203618              True  0.059998     101151                   True   \n",
       "203619              True  0.059998     101151                   True   \n",
       "203620              True  0.059998     101151                   True   \n",
       "\n",
       "        Predicted_Entity_Flag_TextRank_Median  \n",
       "0                                        True  \n",
       "1                                       False  \n",
       "2                                       False  \n",
       "3                                       False  \n",
       "4                                       False  \n",
       "...                                       ...  \n",
       "203616                                   True  \n",
       "203617                                   True  \n",
       "203618                                   True  \n",
       "203619                                   True  \n",
       "203620                                   True  \n",
       "\n",
       "[203618 rows x 20 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rank_eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline using noun phrases to identify entities:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.51      0.68    169575\n",
      "        True       0.29      0.98      0.44     34043\n",
      "\n",
      "    accuracy                           0.59    203618\n",
      "   macro avg       0.64      0.74      0.56    203618\n",
      "weighted avg       0.87      0.59      0.64    203618\n",
      "\n",
      "\n",
      "Use the median TextRank score (0.0083) as a threshold to identify entities.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.57      0.70    169575\n",
      "        True       0.26      0.74      0.38     34043\n",
      "\n",
      "    accuracy                           0.60    203618\n",
      "   macro avg       0.59      0.66      0.54    203618\n",
      "weighted avg       0.81      0.60      0.65    203618\n",
      "\n",
      "\n",
      "Optimize TextRank threshold (0.0) to maximize positive class (Entity = True) F1 score.\n",
      "Range searched - start: 0.0, stop: 0.01946412175465621, step: 0.0001946412175465621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.52      0.68    169575\n",
      "        True       0.27      0.90      0.42     34043\n",
      "\n",
      "    accuracy                           0.58    203618\n",
      "   macro avg       0.62      0.71      0.55    203618\n",
      "weighted avg       0.85      0.58      0.63    203618\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimized_threshold = evaluate(text_rank_eval_df, scoring_method='TextRank', optimization_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    203618.000000\n",
       "mean          0.012249\n",
       "std           0.015581\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.008346\n",
       "75%           0.019464\n",
       "max           0.291369\n",
       "Name: Score, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rank_eval_df['Score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_rank_eval_df['Score'].plot(kind='density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = text_rank_eval_df[text_rank_eval_df['Article_ID'] == 0].sort_values('Score',  ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article_ID</th>\n",
       "      <th>Sentence_ID</th>\n",
       "      <th>Token_ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>POS_Tag</th>\n",
       "      <th>Chunk_Tag</th>\n",
       "      <th>NER_Tag</th>\n",
       "      <th>NER_Tag_ID</th>\n",
       "      <th>NER_Tag_Normalized</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Noun_Phrase</th>\n",
       "      <th>NP_Chunk_Tag</th>\n",
       "      <th>NER_Tag_Flag</th>\n",
       "      <th>Predicted_Phrase</th>\n",
       "      <th>Noun_Phrase_Flag</th>\n",
       "      <th>Score</th>\n",
       "      <th>Phrase_ID</th>\n",
       "      <th>Predicted_Entity_Flag</th>\n",
       "      <th>Predicted_Entity_Flag_TextRank_Median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Article_ID, Sentence_ID, Token_ID, Token, POS_Tag, Chunk_Tag, NER_Tag, NER_Tag_ID, NER_Tag_Normalized, Tags, Prediction, Noun_Phrase, NP_Chunk_Tag, NER_Tag_Flag, Predicted_Phrase, Noun_Phrase_Flag, Score, Phrase_ID, Predicted_Entity_Flag, Predicted_Entity_Flag_TextRank_Median]\n",
       "Index: []"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df[~temp_df['Predicted_Entity_Flag'] & temp_df['Predicted_Entity_Flag_TextRank_Median']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "scaled = min_max_scaler.fit_transform(text_rank_eval_df[['Score']])\n",
    "\n",
    "text_rank_eval_df['Scaled_Score'] = scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rank_eval_df['Inverse_Scaled_Score'] = 1/text_rank_eval_df['Scaled_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize threshold to maximize macro f1\n",
    "optimization_steps = 100\n",
    "start = text_rank_eval_df['Inverse_Scaled_Score'].describe()['min']\n",
    "stop = text_rank_eval_df['Inverse_Scaled_Score'].describe()['50%']\n",
    "step = (stop - start) / optimization_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.036180e+05\n",
       "mean              inf\n",
       "std               NaN\n",
       "min      1.000000e+00\n",
       "25%      1.496954e+01\n",
       "50%      3.491174e+01\n",
       "75%               inf\n",
       "max               inf\n",
       "Name: Inverse_Scaled_Score, dtype: float64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rank_eval_df['Inverse_Scaled_Score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for thresh in np.arange(start, stop, step=step):\n",
    "    predictions.append((thresh, (text_rank_eval_df['Noun_Phrase_Flag'] & (text_rank_eval_df['Inverse_Scaled_Score'] >= thresh)).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_f1_scores = []\n",
    "for prediction in predictions:\n",
    "    report = classification_report(text_rank_eval_df['NER_Tag_Flag'], prediction[1], output_dict=True)\n",
    "    macro_f1_scores.append((prediction[0], report['True']['f1-score'], report['True']['precision'], report['True']['recall'], sum(prediction[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_threshold = max(macro_f1_scores, key=lambda x: x[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.851755398078154"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimize TextRank threshold (11.851755398078154) to maximize positive class (Entity = True) F1 score.\n",
      "Range searched - start: 1.0, stop: 34.91173561899423, step: 0.33911735618994227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.66      0.78    169575\n",
      "        True       0.32      0.77      0.45     34043\n",
      "\n",
      "    accuracy                           0.68    203618\n",
      "   macro avg       0.63      0.72      0.61    203618\n",
      "weighted avg       0.83      0.68      0.72    203618\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scoring_method = 'TextRank'\n",
    "print(f'Optimize {scoring_method} threshold ({optimized_threshold}) to maximize positive class (Entity = True) F1 score.')\n",
    "print(f'Range searched - start: {start}, stop: {stop}, step: {step}')\n",
    "print(classification_report(text_rank_eval_df['NER_Tag_Flag'], (text_rank_eval_df['Noun_Phrase_Flag'] & (text_rank_eval_df['Inverse_Scaled_Score'] >= optimized_threshold))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is precision going down as we increase the threshold? Are higher thresholds associated with more false positives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "above_thresh_df = text_rank_eval_df[(text_rank_eval_df['Score'] >= text_rank_eval_df['Score'].describe()['50%']) & text_rank_eval_df['Predicted_Entity_Flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "below_thresh_df = text_rank_eval_df[(text_rank_eval_df['Score'] < text_rank_eval_df['Score'].describe()['50%']) & text_rank_eval_df['Predicted_Entity_Flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2567204574591482"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "above_thresh_df['NER_Tag_Flag'].sum() / len(above_thresh_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45319693094629154"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "below_thresh_df['NER_Tag_Flag'].sum() / len(below_thresh_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article_ID</th>\n",
       "      <th>Sentence_ID</th>\n",
       "      <th>Token_ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>POS_Tag</th>\n",
       "      <th>Chunk_Tag</th>\n",
       "      <th>NER_Tag</th>\n",
       "      <th>NER_Tag_ID</th>\n",
       "      <th>NER_Tag_Normalized</th>\n",
       "      <th>Tags</th>\n",
       "      <th>...</th>\n",
       "      <th>Noun_Phrase</th>\n",
       "      <th>NP_Chunk_Tag</th>\n",
       "      <th>NER_Tag_Flag</th>\n",
       "      <th>Predicted_Phrase</th>\n",
       "      <th>Noun_Phrase_Flag</th>\n",
       "      <th>Score</th>\n",
       "      <th>Phrase_ID</th>\n",
       "      <th>Predicted_Entity_Flag</th>\n",
       "      <th>Predicted_Entity_Flag_TextRank_Median</th>\n",
       "      <th>Scaled_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EU</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ORG</td>\n",
       "      <td>(EU, NNP, I-NP)</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>EU</td>\n",
       "      <td>True</td>\n",
       "      <td>0.015790</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.054194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rejects</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(rejects, VBZ, I-VP)</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rejects</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>German</td>\n",
       "      <td>JJ</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MISC</td>\n",
       "      <td>(German, JJ, I-NP)</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>German</td>\n",
       "      <td>True</td>\n",
       "      <td>0.006349</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.021789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>call</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(call, NN, I-NP)</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>call</td>\n",
       "      <td>True</td>\n",
       "      <td>0.006349</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.021789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(to, TO, I-VP)</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>to</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203616</th>\n",
       "      <td>945</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>three</td>\n",
       "      <td>CD</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(three, CD, I-NP)</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>three</td>\n",
       "      <td>True</td>\n",
       "      <td>0.059998</td>\n",
       "      <td>101151</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.205919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203617</th>\n",
       "      <td>945</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>23497.0</td>\n",
       "      <td>ORG</td>\n",
       "      <td>(Swansea, NN, I-NP)</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>True</td>\n",
       "      <td>0.059998</td>\n",
       "      <td>101151</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.205919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203618</th>\n",
       "      <td>945</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CD</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(1, CD, I-NP)</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.059998</td>\n",
       "      <td>101151</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.205919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203619</th>\n",
       "      <td>945</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>23498.0</td>\n",
       "      <td>ORG</td>\n",
       "      <td>(Lincoln, NNP, I-NP)</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>True</td>\n",
       "      <td>0.059998</td>\n",
       "      <td>101151</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.205919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203620</th>\n",
       "      <td>945</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>CD</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(2, CD, I-NP)</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.059998</td>\n",
       "      <td>101151</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.205919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203618 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Article_ID  Sentence_ID  Token_ID    Token POS_Tag Chunk_Tag NER_Tag  \\\n",
       "0                0            0         0       EU     NNP      I-NP   I-ORG   \n",
       "1                0            0         1  rejects     VBZ      I-VP       O   \n",
       "2                0            0         2   German      JJ      I-NP  I-MISC   \n",
       "3                0            0         3     call      NN      I-NP       O   \n",
       "4                0            0         4       to      TO      I-VP       O   \n",
       "...            ...          ...       ...      ...     ...       ...     ...   \n",
       "203616         945            6         1    three      CD      I-NP       O   \n",
       "203617         945            7         0  Swansea      NN      I-NP   I-ORG   \n",
       "203618         945            7         1        1      CD      I-NP       O   \n",
       "203619         945            7         2  Lincoln     NNP      I-NP   I-ORG   \n",
       "203620         945            7         3        2      CD      I-NP       O   \n",
       "\n",
       "        NER_Tag_ID NER_Tag_Normalized                  Tags  ... Noun_Phrase  \\\n",
       "0              0.0                ORG       (EU, NNP, I-NP)  ...        True   \n",
       "1              NaN                  O  (rejects, VBZ, I-VP)  ...       False   \n",
       "2              1.0               MISC    (German, JJ, I-NP)  ...        True   \n",
       "3              NaN                  O      (call, NN, I-NP)  ...        True   \n",
       "4              NaN                  O        (to, TO, I-VP)  ...       False   \n",
       "...            ...                ...                   ...  ...         ...   \n",
       "203616         NaN                  O     (three, CD, I-NP)  ...        True   \n",
       "203617     23497.0                ORG   (Swansea, NN, I-NP)  ...        True   \n",
       "203618         NaN                  O         (1, CD, I-NP)  ...        True   \n",
       "203619     23498.0                ORG  (Lincoln, NNP, I-NP)  ...        True   \n",
       "203620         NaN                  O         (2, CD, I-NP)  ...        True   \n",
       "\n",
       "        NP_Chunk_Tag  NER_Tag_Flag  Predicted_Phrase Noun_Phrase_Flag  \\\n",
       "0               True          True                EU             True   \n",
       "1              False         False           rejects            False   \n",
       "2               True          True            German             True   \n",
       "3               True         False              call             True   \n",
       "4              False         False                to            False   \n",
       "...              ...           ...               ...              ...   \n",
       "203616          True         False             three             True   \n",
       "203617          True          True           Swansea             True   \n",
       "203618          True         False                 1             True   \n",
       "203619          True          True           Lincoln             True   \n",
       "203620          True         False                 2             True   \n",
       "\n",
       "           Score  Phrase_ID  Predicted_Entity_Flag  \\\n",
       "0       0.015790          0                   True   \n",
       "1       0.000000          1                  False   \n",
       "2       0.006349          2                   True   \n",
       "3       0.006349          2                   True   \n",
       "4       0.000000          3                  False   \n",
       "...          ...        ...                    ...   \n",
       "203616  0.059998     101151                   True   \n",
       "203617  0.059998     101151                   True   \n",
       "203618  0.059998     101151                   True   \n",
       "203619  0.059998     101151                   True   \n",
       "203620  0.059998     101151                   True   \n",
       "\n",
       "        Predicted_Entity_Flag_TextRank_Median  Scaled_Score  \n",
       "0                                        True      0.054194  \n",
       "1                                       False      0.000000  \n",
       "2                                       False      0.021789  \n",
       "3                                       False      0.021789  \n",
       "4                                       False      0.000000  \n",
       "...                                       ...           ...  \n",
       "203616                                   True      0.205919  \n",
       "203617                                   True      0.205919  \n",
       "203618                                   True      0.205919  \n",
       "203619                                   True      0.205919  \n",
       "203620                                   True      0.205919  \n",
       "\n",
       "[203618 rows x 21 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rank_eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python - Knowledge Graphs",
   "language": "python",
   "name": "knowledge-graphs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
