{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tmorrill002/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/tmorrill002/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     /Users/tmorrill002/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tmorrill002/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import conll2000\n",
    "\n",
    "import kg.ner.utils as utils\n",
    "from kg.ner.unsupervised import NounPhraseDetection, EntityDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '/Users/tmorrill002/Documents/datasets/conll/transformed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = utils.load_train_data(data_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What fraction of NER tags are Noun Phrases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_dict['train.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns_over_NER(df, noun_col = 'Chunk_Tag', ner_col = 'NER_Tag_Normalized'):\n",
    "    ner_df = df[df[ner_col] != 'O']\n",
    "    noun_phrase_token_count = len(ner_df[(ner_df[noun_col] == 'I-NP') | (ner_df[noun_col] == 'B-NP')])\n",
    "    print(f'Count of noun phrase tokens among NER tokens: {noun_phrase_token_count}')\n",
    "    print(f'Count of NER tokens: {len(ner_df)}')\n",
    "    print(f'Percent of NER tokens that are part of noun phrases: {round(noun_phrase_token_count / len(ner_df),4) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of noun phrase tokens among NER tokens: 33054\n",
      "Count of NER tokens: 34043\n",
      "Percent of NER tokens that are part of noun phrases: 97.09%\n"
     ]
    }
   ],
   "source": [
    "nouns_over_NER(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What fraction of Noun Phrase tokens are NER tagged?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NER_over_nouns(df, noun_col = 'Chunk_Tag', ner_col = 'NER_Tag_Normalized'):\n",
    "    noun_phrase_df = df[(df[noun_col] == 'I-NP') | (df[noun_col] == 'B-NP')]\n",
    "    ner_tag_token_count = len(noun_phrase_df[noun_phrase_df[ner_col] != 'O'])\n",
    "    print(f'Count of NER tokens among noun phrase tokens: {ner_tag_token_count}')\n",
    "    print(f'Count of noun phrase tokens: {len(noun_phrase_df)}')\n",
    "    print(f'Percent of noun phrase tokens that are part of NER tags: {round(ner_tag_token_count / len(noun_phrase_df), 4) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of NER tokens among noun phrase tokens: 33054\n",
      "Count of noun phrase tokens: 124032\n",
      "Percent of noun phrase tokens that are part of NER tags: 26.650000000000002%\n"
     ]
    }
   ],
   "source": [
    "NER_over_nouns(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "1. NER Tags are almost exclusively noun phrases (97%) -> noun phrase candidates will yield high recall\n",
    "2. Noun phrases encompass a lot more than NER tags -> noun phrase candidates will yield low precision and other techniques should be used to reduce the number of false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Unsupervised Noun Phrase Detection Against CoNLL-2000 and CoNLL-2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conll_2000_test_sentences = conll2000.chunked_sents('test.txt', chunk_types=['NP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_parser = NounPhraseDetection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  87.7%%\n",
      "    Precision:     70.6%%\n",
      "    Recall:        67.8%%\n",
      "    F-Measure:     69.2%%\n"
     ]
    }
   ],
   "source": [
    "print(chunk_parser.evaluate(conll_2000_test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate(x):\n",
    "    return (x['Token'], x['POS_Tag'], x['Chunk_Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Tags'] = train_df.apply(consolidate, axis=1) #passes a Series object, row-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth labeled data containing (token, pos, chunk), used for evaluation\n",
    "train_conll_2003 = train_df.groupby(['Article_ID', 'Sentence_ID'], )['Tags'].apply(list).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos tagged sentences only containing (token, pos), used to make predictions\n",
    "train_conll_2003_pos_tags = []\n",
    "for sentence in train_conll_2003:\n",
    "    temp_sentence = []\n",
    "    for token, pos, chunk in sentence:\n",
    "        temp_sentence.append((token, pos))\n",
    "    train_conll_2003_pos_tags.append(temp_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples must be in \"tree\" format to use evaluation code\n",
    "trees = []\n",
    "for example in train_conll_2003:\n",
    "    trees.append(nltk.chunk.conlltags2tree(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  67.4%%\n",
      "    Precision:     80.5%%\n",
      "    Recall:        43.7%%\n",
      "    F-Measure:     56.7%%\n"
     ]
    }
   ],
   "source": [
    "# getting harmed here because B-NP tags aren't marked appropriately in CoNLL-2003\n",
    "print(chunk_parser.evaluate(trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_trees = []\n",
    "for example in train_conll_2003_pos_tags:\n",
    "    prediction_trees.append(chunk_parser.parse(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for sentence in prediction_trees:\n",
    "    predictions.append(nltk.chunk.tree2conlltags(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = [prediction for sentence in predictions for prediction in sentence ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Prediction'] = flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Prediction'] = train_df['Prediction'].apply(lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Noun_Phrase'] = train_df['Prediction'] != 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of noun phrase tokens among NER tokens: 33030\n",
      "Count of NER tokens: 34043\n",
      "Percent of NER tokens that are part of noun phrases: 97.02%\n"
     ]
    }
   ],
   "source": [
    "nouns_over_NER(train_df, 'Prediction', 'NER_Tag_Normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of NER tokens among noun phrase tokens: 33030\n",
      "Count of noun phrase tokens: 124428\n",
      "Percent of noun phrase tokens that are part of NER tags: 26.55%\n"
     ]
    }
   ],
   "source": [
    "NER_over_nouns(train_df, 'Prediction', 'NER_Tag_Normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['NP_Chunk_Tag'] = (train_df['Chunk_Tag'] == 'I-NP') | (train_df['Chunk_Tag'] == 'B-NP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9570476522559068"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agreement between existing ConLL-2003 noun phrase tags and the predicted tags\n",
    "(train_df['Noun_Phrase'] == train_df['NP_Chunk_Tag']).sum() / len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate TF-IDF Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_extractor = EntityDetection(chunk_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article_ID</th>\n",
       "      <th>Sentence_ID</th>\n",
       "      <th>Token_ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>POS_Tag</th>\n",
       "      <th>Chunk_Tag</th>\n",
       "      <th>NER_Tag</th>\n",
       "      <th>NER_Tag_ID</th>\n",
       "      <th>NER_Tag_Normalized</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Noun_Phrase</th>\n",
       "      <th>NP_Chunk_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EU</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ORG</td>\n",
       "      <td>(EU, NNP, I-NP)</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rejects</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(rejects, VBZ, I-VP)</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>German</td>\n",
       "      <td>JJ</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MISC</td>\n",
       "      <td>(German, JJ, I-NP)</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>call</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(call, NN, I-NP)</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(to, TO, I-VP)</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203616</th>\n",
       "      <td>945</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>three</td>\n",
       "      <td>CD</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(three, CD, I-NP)</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203617</th>\n",
       "      <td>945</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>23497.0</td>\n",
       "      <td>ORG</td>\n",
       "      <td>(Swansea, NN, I-NP)</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203618</th>\n",
       "      <td>945</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CD</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(1, CD, I-NP)</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203619</th>\n",
       "      <td>945</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>23498.0</td>\n",
       "      <td>ORG</td>\n",
       "      <td>(Lincoln, NNP, I-NP)</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203620</th>\n",
       "      <td>945</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>CD</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(2, CD, I-NP)</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203621 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Article_ID  Sentence_ID  Token_ID    Token POS_Tag Chunk_Tag NER_Tag  \\\n",
       "0                0            0         0       EU     NNP      I-NP   I-ORG   \n",
       "1                0            0         1  rejects     VBZ      I-VP       O   \n",
       "2                0            0         2   German      JJ      I-NP  I-MISC   \n",
       "3                0            0         3     call      NN      I-NP       O   \n",
       "4                0            0         4       to      TO      I-VP       O   \n",
       "...            ...          ...       ...      ...     ...       ...     ...   \n",
       "203616         945            6         1    three      CD      I-NP       O   \n",
       "203617         945            7         0  Swansea      NN      I-NP   I-ORG   \n",
       "203618         945            7         1        1      CD      I-NP       O   \n",
       "203619         945            7         2  Lincoln     NNP      I-NP   I-ORG   \n",
       "203620         945            7         3        2      CD      I-NP       O   \n",
       "\n",
       "        NER_Tag_ID NER_Tag_Normalized                  Tags Prediction  \\\n",
       "0              0.0                ORG       (EU, NNP, I-NP)       B-NP   \n",
       "1              NaN                  O  (rejects, VBZ, I-VP)          O   \n",
       "2              1.0               MISC    (German, JJ, I-NP)       B-NP   \n",
       "3              NaN                  O      (call, NN, I-NP)       I-NP   \n",
       "4              NaN                  O        (to, TO, I-VP)          O   \n",
       "...            ...                ...                   ...        ...   \n",
       "203616         NaN                  O     (three, CD, I-NP)       I-NP   \n",
       "203617     23497.0                ORG   (Swansea, NN, I-NP)       B-NP   \n",
       "203618         NaN                  O         (1, CD, I-NP)       I-NP   \n",
       "203619     23498.0                ORG  (Lincoln, NNP, I-NP)       I-NP   \n",
       "203620         NaN                  O         (2, CD, I-NP)       I-NP   \n",
       "\n",
       "        Noun_Phrase  NP_Chunk_Tag  \n",
       "0              True          True  \n",
       "1             False         False  \n",
       "2              True          True  \n",
       "3              True          True  \n",
       "4             False         False  \n",
       "...             ...           ...  \n",
       "203616         True          True  \n",
       "203617         True          True  \n",
       "203618         True          True  \n",
       "203619         True          True  \n",
       "203620         True          True  \n",
       "\n",
       "[203621 rows x 13 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather up articles\n",
    "articles = train_df.groupby(['Article_ID'], )['Token'].apply(lambda x: ' '.join([str(y) for y in list(x)])).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_extractor.fit_tfidf(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_phrases = []\n",
    "for article in articles:\n",
    "    for candidate in entity_extractor.candidates(article):\n",
    "        candidate_phrases.append(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at first article\n",
    "candidates = entity_extractor.candidates(articles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = entity_extractor.score_phrases(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored = list(set(zip(candidates, scores.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored.sort(key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article_ID</th>\n",
       "      <th>Sentence_ID</th>\n",
       "      <th>Token_ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>POS_Tag</th>\n",
       "      <th>Chunk_Tag</th>\n",
       "      <th>NER_Tag</th>\n",
       "      <th>NER_Tag_ID</th>\n",
       "      <th>NER_Tag_Normalized</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Noun_Phrase</th>\n",
       "      <th>NP_Chunk_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>I-PP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(to, TO, I-PP)</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>sheep</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(sheep, NN, I-NP)</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(., ., O)</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>8.0</td>\n",
       "      <td>LOC</td>\n",
       "      <td>(Germany, NNP, I-NP)</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>'s</td>\n",
       "      <td>POS</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>('s, POS, B-NP)</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>representative</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(representative, NN, I-NP)</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>I-PP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(to, TO, I-PP)</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>(the, DT, I-NP)</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>European</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>9.0</td>\n",
       "      <td>ORG</td>\n",
       "      <td>(European, NNP, I-NP)</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Union</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>9.0</td>\n",
       "      <td>ORG</td>\n",
       "      <td>(Union, NNP, I-NP)</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Article_ID  Sentence_ID  Token_ID           Token POS_Tag Chunk_Tag  \\\n",
       "40           0            3        27              to      TO      I-PP   \n",
       "41           0            3        28           sheep      NN      I-NP   \n",
       "42           0            3        29               .       .         O   \n",
       "43           0            4         0         Germany     NNP      I-NP   \n",
       "44           0            4         1              's     POS      B-NP   \n",
       "45           0            4         2  representative      NN      I-NP   \n",
       "46           0            4         3              to      TO      I-PP   \n",
       "47           0            4         4             the      DT      I-NP   \n",
       "48           0            4         5        European     NNP      I-NP   \n",
       "49           0            4         6           Union     NNP      I-NP   \n",
       "\n",
       "   NER_Tag  NER_Tag_ID NER_Tag_Normalized                        Tags  \\\n",
       "40       O         NaN                  O              (to, TO, I-PP)   \n",
       "41       O         NaN                  O           (sheep, NN, I-NP)   \n",
       "42       O         NaN                  O                   (., ., O)   \n",
       "43   I-LOC         8.0                LOC        (Germany, NNP, I-NP)   \n",
       "44       O         NaN                  O             ('s, POS, B-NP)   \n",
       "45       O         NaN                  O  (representative, NN, I-NP)   \n",
       "46       O         NaN                  O              (to, TO, I-PP)   \n",
       "47       O         NaN                  O             (the, DT, I-NP)   \n",
       "48   I-ORG         9.0                ORG       (European, NNP, I-NP)   \n",
       "49   I-ORG         9.0                ORG          (Union, NNP, I-NP)   \n",
       "\n",
       "   Prediction  Noun_Phrase  NP_Chunk_Tag  \n",
       "40          O        False         False  \n",
       "41       B-NP         True          True  \n",
       "42          O        False         False  \n",
       "43       B-NP         True          True  \n",
       "44       I-NP         True          True  \n",
       "45       I-NP         True          True  \n",
       "46          O        False         False  \n",
       "47       B-NP         True          True  \n",
       "48       I-NP         True          True  \n",
       "49       I-NP         True          True  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['Article_ID'] == 0].iloc[40:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EU rejects German call to boycott British lamb . Peter Blackburn BRUSSELS 1996-08-22 The European Commission said on Thursday it disagreed with German advice to consumers to shun British lamb until scientists determine whether mad cow disease can be transmitted to sheep . Germany \\'s representative to the European Union \\'s veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer . \" We do n\\'t support any such recommendation because we do n\\'t see any grounds for it , \" the Commission \\'s chief spokesman Nikolaus van der Pas told a news briefing . He said further scientific study was required and if it was found that action was needed it should be taken by the European Union . He said a proposal last month by EU Farm Commissioner Franz Fischler to ban sheep brains , spleens and spinal cords from the human and animal food chains was a highly specific and precautionary move to protect human health . Fischler proposed EU-wide measures after reports from Britain and France that under laboratory conditions sheep could contract Bovine Spongiform Encephalopathy ( BSE ) -- mad cow disease . But Fischler agreed to review his proposal after the EU \\'s standing veterinary committee , mational animal health officials , questioned if such action was justified as there was only a slight risk to human health . Spanish Farm Minister Loyola de Palacio had earlier accused Fischler at an EU farm ministers \\' meeting of causing unjustified alarm through \" dangerous generalisation . \" . Only France and Britain backed Fischler \\'s proposal . The EU \\'s scientific veterinary and multidisciplinary committees are due to re-examine the issue early next month and make recommendations to the senior veterinary officials . Sheep have long been known to contract scrapie , a brain-wasting disease similar to BSE which is believed to have been transferred to cattle through feed containing animal waste . British farmers denied on Thursday there was any danger to human health from their sheep , but expressed concern that German government advice to consumers to avoid British lamb might influence consumers across Europe . \" What we have to be extremely careful of is how other countries are going to take Germany \\'s lead , \" Welsh National Farmers \\' Union ( NFU ) chairman John Lloyd Jones said on BBC radio . Bonn has led efforts to protect public health after consumer confidence collapsed in March after a British report suggested humans could contract an illness similar to mad cow disease by eating contaminated beef . Germany imported 47,600 sheep from Britain last year , nearly half of total imports . It brought in 4,275 tonnes of British mutton , some 10 percent of overall imports .'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('careful', 7.160151912626133),\n",
       " ('clearer', 7.160151912626133),\n",
       " ('Palacio', 7.160151912626133),\n",
       " ('NFU', 7.160151912626133),\n",
       " ('Fischler', 6.754686804517968),\n",
       " ('recommendations', 6.754686804517968),\n",
       " ('sheepmeat', 6.754686804517968),\n",
       " ('unjustified alarm', 6.702006546689056),\n",
       " ('sheep brains', 6.610845768292078),\n",
       " ('humans', 6.467004732066187),\n",
       " ('consumers', 6.467004732066187),\n",
       " ('dangerous generalisation', 6.264272178012106),\n",
       " (\"Fischler 's proposal\", 6.264272178012105),\n",
       " ('scientists', 6.243861180751978),\n",
       " ('BSE', 6.243861180751978),\n",
       " ('scientific study', 6.120431141786215),\n",
       " ('animal waste', 6.061539623958024),\n",
       " ('EU Farm Commissioner Franz Fischler', 5.911075961208344),\n",
       " ('contract Bovine Spongiform Encephalopathy', 5.910110914068893),\n",
       " ('beef', 5.907388944130765),\n",
       " ('laboratory conditions sheep', 5.883938113796435),\n",
       " ('contract scrapie', 5.831773459268803),\n",
       " ('BBC radio', 5.758471722172866),\n",
       " ('mad cow disease', 5.643951967792901),\n",
       " ('a slight risk', 5.57112499745216),\n",
       " ('EU-wide measures', 5.554064112143199),\n",
       " ('feed', 5.550714000192032),\n",
       " ('a brain-wasting disease similar', 5.53652441673738),\n",
       " ('cow disease', 5.512233479623969),\n",
       " ('British lamb', 5.459553221795055),\n",
       " ('EU', 5.4554038203877075),\n",
       " ('consumer confidence', 5.32837108956131),\n",
       " ('Spanish Farm Minister Loyola', 5.306885482111128),\n",
       " ('overall imports', 5.282467314934749),\n",
       " ('spleens and spinal cords', 5.2711102712009605),\n",
       " ('mational animal health officials', 5.2670261663710365),\n",
       " ('British mutton', 5.256820667740973),\n",
       " ('4,275 tonnes', 5.25129574964768),\n",
       " ('47,600 sheep', 5.20090665203292),\n",
       " ('efforts', 5.145248892083869),\n",
       " ('German advice', 5.088584549430367),\n",
       " (\"The EU 's scientific veterinary and multidisciplinary committees\",\n",
       "  4.9388985957545755),\n",
       " ('concern', 4.908860114019638),\n",
       " ('specific and precautionary move', 4.840418621765684),\n",
       " (\"Welsh National Farmers ' Union\", 4.816066417650372),\n",
       " (\"the European Union 's veterinary committee Werner Zwingmann\",\n",
       "  4.806021701323124),\n",
       " ('chairman John Lloyd Jones', 4.793180575124202),\n",
       " ('a news briefing', 4.76640604123511),\n",
       " ('Bonn', 4.762256639827763),\n",
       " ('total imports', 4.760194781235832),\n",
       " ('any such recommendation', 4.748398964085936),\n",
       " (\"Germany 's representative\", 4.726384687398341),\n",
       " ('any grounds', 4.721599961890266),\n",
       " ('the scientific advice', 4.697994963016169),\n",
       " (\"the EU 's standing veterinary committee\", 4.655514316346687),\n",
       " (\"the Commission 's chief spokesman Nikolaus van der Pas\", 4.652992286260471),\n",
       " ('British farmers', 4.607179175675842),\n",
       " ('human health', 4.595942747749813),\n",
       " ('any danger', 4.5432624899209),\n",
       " ('their sheep', 4.486598147267399),\n",
       " ('reports', 4.4860032631996045),\n",
       " ('But Fischler', 4.469052487361763),\n",
       " ('Wednesday consumers', 4.4411122581645355),\n",
       " ('action', 4.419311888700932),\n",
       " ('public health', 4.413621190955858),\n",
       " (\"an EU farm ministers ' meeting\", 4.409286365924787),\n",
       " ('Europe', 4.387563190386352),\n",
       " ('German government advice', 4.38255542315348),\n",
       " ('such action', 4.330846534621393),\n",
       " ('contract an illness similar', 4.32539173312701),\n",
       " ('March', 4.269780154729968),\n",
       " ('his proposal', 4.1259391185040775),\n",
       " ('the human and animal food chains', 4.112372515567334),\n",
       " ('German call', 4.048863778590449),\n",
       " ('a British report', 3.9140319951158977),\n",
       " ('a proposal last month', 3.8679932448630403),\n",
       " ('the senior veterinary officials', 3.7946976926464884),\n",
       " (\"Germany 's lead\", 3.7445798243209847),\n",
       " ('countries other', 3.7353537302218305),\n",
       " ('other countries', 3.7353537302218305),\n",
       " ('Germany', 3.678911823290441),\n",
       " ('Britain', 3.6636443511596526),\n",
       " ('due', 3.6337913880099717),\n",
       " ('half', 3.5628396520376873),\n",
       " ('Peter Blackburn BRUSSELS 1996-08-22 The European Commission',\n",
       "  3.2592037547112853),\n",
       " ('the European Union', 2.975329928061347),\n",
       " ('We', 2.9260454080288736),\n",
       " ('France and Britain', 2.901671670990041),\n",
       " ('Britain and France', 2.901671670990041),\n",
       " ('Britain last year', 2.8637204184845437),\n",
       " ('some 10 percent', 2.847851614940197),\n",
       " ('the issue', 2.6378024499094193),\n",
       " ('next month and', 2.627095638703135),\n",
       " ('Thursday', 2.36023764984553),\n",
       " ('Thursday it', 2.1835489839869417),\n",
       " ('He', 2.169719325847397),\n",
       " ('It', 2.006860318128354)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python - Knowledge Graphs",
   "language": "python",
   "name": "knowledge-graphs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
