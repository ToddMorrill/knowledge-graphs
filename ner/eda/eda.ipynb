{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore CoNLL-2003 NER Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE_PATH = '/Users/tmorrill002/Documents/datasets/conll/raw/ner/eng.train'\n",
    "VAL_FILE_PATH = '/Users/tmorrill002/Documents/datasets/conll/raw/ner/eng.testa'\n",
    "TEST_FILE_PATH = '/Users/tmorrill002/Documents/datasets/conll/raw/ner/eng.testb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = f.read()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data(TRAIN_FILE_PATH)\n",
    "val_data = read_data(VAL_FILE_PATH)\n",
    "test_data = read_data(TEST_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(data):\n",
    "    return data.split('-DOCSTART- -X- -X- O\\n\\n')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = split_documents(train_data)\n",
    "val_data = split_documents(val_data)\n",
    "test_data = split_documents(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(data):\n",
    "    split_data = []\n",
    "    for doc in data:\n",
    "        split_data.append(doc.split('\\n\\n'))\n",
    "    return split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = split_sentences(train_data)\n",
    "val_data = split_sentences(val_data)\n",
    "test_data = split_sentences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tokens(data):\n",
    "    split_data = []\n",
    "    for doc in data:\n",
    "        split_doc = []\n",
    "        for sentence in doc:\n",
    "            tokens = sentence.split('\\n')\n",
    "            # remove blank lines\n",
    "            tokens =  [tok for tok in tokens if tok != '']\n",
    "            split_doc.append(tokens)\n",
    "        split_data.append(split_doc)\n",
    "    return split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = split_tokens(train_data)\n",
    "val_data = split_tokens(val_data)\n",
    "test_data = split_tokens(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tags(data):\n",
    "    split_data = []\n",
    "    for doc in data:\n",
    "        split_doc = []\n",
    "        for sentence in doc:\n",
    "            split_sentence = []\n",
    "            for example in sentence:\n",
    "                tags = example.split(' ')\n",
    "                split_sentence.append(tags)\n",
    "            split_doc.append(split_sentence)\n",
    "        split_data.append(split_doc)\n",
    "    return split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = split_tags(train_data)\n",
    "val_data = split_tags(val_data)\n",
    "test_data = split_tags(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer to original paper for data checks\n",
    "# https://www.aclweb.org/anthology/W03-0419.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Data Checks](data_checks.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_ARTICLES = 946\n",
    "VAL_ARTICLES = 216\n",
    "TEST_ARTICLES = 231\n",
    "assert len(train_data) == TRAIN_ARTICLES\n",
    "assert len(val_data) == VAL_ARTICLES\n",
    "assert len(test_data) == TEST_ARTICLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SENTENCES = 14_987\n",
    "VAL_SENTENCES = 3_466\n",
    "TEST_SENTENCES = 3_684\n",
    "assert TRAIN_SENTENCES == sum([len(doc)for doc in train_data])\n",
    "assert VAL_SENTENCES == sum([len(doc)for doc in val_data])\n",
    "assert TEST_SENTENCES == sum([len(doc)for doc in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_count(data):\n",
    "    token_count = 0\n",
    "    for doc in data:\n",
    "        for sentence in doc:\n",
    "            token_count += len(sentence)\n",
    "    return token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TOKENS = 203_621\n",
    "VAL_TOKENS = 51_362\n",
    "TEST_TOKENS = 46_435\n",
    "assert TRAIN_TOKENS == token_count(train_data)\n",
    "assert VAL_TOKENS == token_count(val_data)\n",
    "assert TEST_TOKENS == token_count(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: clean this function up\n",
    "def count_tags(data):\n",
    "    tag_counts = {'LOC': 0, 'MISC': 0, 'ORG': 0, 'PER': 0}\n",
    "    for doc in data:\n",
    "        for sentence in doc:\n",
    "            i = 0\n",
    "            break_count = len(sentence)\n",
    "            for _ in range(len(sentence)):\n",
    "                if i == break_count:\n",
    "                    break\n",
    "                word, pos_tag, chunk_tag, ner_tag = sentence[i]\n",
    "                # check if it's a LOC tag\n",
    "                if ner_tag == 'I-LOC' or ner_tag == 'B-LOC':\n",
    "                    tag_counts['LOC'] += 1\n",
    "                    ner_tag = 'I-LOC'\n",
    "                    while ner_tag == 'I-LOC':\n",
    "                        # advance the index by one and check the ner_tag \n",
    "                        i += 1\n",
    "                        if i == break_count:\n",
    "                            break\n",
    "                        word, pos_tag, chunk_tag, ner_tag = sentence[i]\n",
    "                # check if it's a MISC tag\n",
    "                elif ner_tag == 'I-MISC' or ner_tag == 'B-MISC':\n",
    "                    tag_counts['MISC'] += 1\n",
    "                    ner_tag = 'I-MISC'\n",
    "                    while ner_tag == 'I-MISC':\n",
    "                        # advance the index by one and check the ner_tag \n",
    "                        i += 1\n",
    "                        if i == break_count:\n",
    "                            break\n",
    "                        word, pos_tag, chunk_tag, ner_tag = sentence[i]\n",
    "                # check if it's an ORG tag\n",
    "                elif ner_tag == 'I-ORG' or ner_tag == 'B-ORG':\n",
    "                    tag_counts['ORG'] += 1\n",
    "                    ner_tag = 'I-ORG'\n",
    "                    while ner_tag == 'I-ORG':\n",
    "                        # advance the index by one and check the ner_tag \n",
    "                        i += 1\n",
    "                        if i == break_count:\n",
    "                            break\n",
    "                        word, pos_tag, chunk_tag, ner_tag = sentence[i]\n",
    "                # check if it's an PER tag\n",
    "                elif ner_tag == 'I-PER' or ner_tag == 'B-PER':\n",
    "                    tag_counts['PER'] += 1\n",
    "                    ner_tag = 'I-PER'\n",
    "                    while ner_tag == 'I-PER':\n",
    "                        # advance the index by one and check the ner_tag \n",
    "                        i += 1\n",
    "                        if i == break_count:\n",
    "                            break\n",
    "                        word, pos_tag, chunk_tag, ner_tag = sentence[i]\n",
    "                else:\n",
    "                    i += 1\n",
    "    return tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TAGS = {'LOC': 7140, 'MISC': 3438, 'ORG': 6321, 'PER': 6600}\n",
    "VAL_TAGS = {'LOC': 1837, 'MISC': 922, 'ORG': 1341, 'PER': 1842}\n",
    "TEST_TAGS = {'LOC': 1668, 'MISC': 702, 'ORG': 1661, 'PER': 1617}\n",
    "assert TRAIN_TAGS == count_tags(train_data)\n",
    "assert VAL_TAGS == count_tags(val_data)\n",
    "assert TEST_TAGS == count_tags(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: clean this function up\n",
    "def id_tags(data):\n",
    "    global_tag_id = 0\n",
    "    for j, doc in enumerate(data):\n",
    "        for k, sentence in enumerate(doc):\n",
    "            i = 0\n",
    "            break_count = len(sentence)\n",
    "            for _ in range(len(sentence)):\n",
    "                # print(i)\n",
    "                if i == break_count:\n",
    "                    break\n",
    "                word, pos_tag, chunk_tag, ner_tag = sentence[i]\n",
    "                # check if it's a LOC tag\n",
    "                if ner_tag == 'I-LOC' or ner_tag == 'B-LOC':\n",
    "                    data[j][k][i] = [word, pos_tag, chunk_tag, ner_tag, global_tag_id]\n",
    "                    temp_tag = 'I-LOC'\n",
    "                    m = 0\n",
    "                    while temp_tag == 'I-LOC':\n",
    "                        if m != 0:\n",
    "                            data[j][k][i] = [word, pos_tag, chunk_tag, temp_tag, global_tag_id]\n",
    "                        # advance the index by one and check the ner_tag \n",
    "                        i += 1\n",
    "                        if i == break_count:\n",
    "                            break\n",
    "                        word, pos_tag, chunk_tag, temp_tag = sentence[i]\n",
    "                        m += 1\n",
    "                    global_tag_id += 1\n",
    "                # check if it's a MISC tag\n",
    "                elif ner_tag == 'I-MISC' or ner_tag == 'B-MISC':\n",
    "                    data[j][k][i] = [word, pos_tag, chunk_tag, ner_tag, global_tag_id]\n",
    "                    temp_tag = 'I-MISC'\n",
    "                    m = 0\n",
    "                    while temp_tag == 'I-MISC':\n",
    "                        if m != 0:\n",
    "                            data[j][k][i] = [word, pos_tag, chunk_tag, temp_tag, global_tag_id]\n",
    "                        # advance the index by one and check the ner_tag \n",
    "                        i += 1\n",
    "                        if i == break_count:\n",
    "                            break\n",
    "                        word, pos_tag, chunk_tag, temp_tag = sentence[i]\n",
    "                        m += 1\n",
    "                    global_tag_id += 1\n",
    "                # check if it's an ORG tag\n",
    "                elif ner_tag == 'I-ORG' or ner_tag == 'B-ORG':\n",
    "                    # print('I-ORG', i)\n",
    "                    data[j][k][i] = [word, pos_tag, chunk_tag, ner_tag, global_tag_id]\n",
    "                    temp_tag = 'I-ORG'\n",
    "                    m = 0\n",
    "                    while temp_tag == 'I-ORG':\n",
    "                        if m != 0:\n",
    "                            # print(global_tag_id)\n",
    "                            data[j][k][i] = [word, pos_tag, chunk_tag, temp_tag, global_tag_id]\n",
    "                        # advance the index by one and check the ner_tag \n",
    "                        i += 1\n",
    "                        if i == break_count:\n",
    "                            break\n",
    "                        word, pos_tag, chunk_tag, temp_tag = sentence[i]\n",
    "                        # print(sentence[i])\n",
    "                        m += 1\n",
    "                    global_tag_id += 1\n",
    "                # check if it's an PER tag\n",
    "                elif ner_tag == 'I-PER' or ner_tag == 'B-PER':\n",
    "                    data[j][k][i] = [word, pos_tag, chunk_tag, ner_tag, global_tag_id]\n",
    "                    temp_tag = 'I-PER'\n",
    "                    m = 0\n",
    "                    while temp_tag == 'I-PER':\n",
    "                        if m != 0:\n",
    "                            data[j][k][i] = [word, pos_tag, chunk_tag, temp_tag, global_tag_id]\n",
    "                        # advance the index by one and check the ner_tag \n",
    "                        i += 1\n",
    "                        if i == break_count:\n",
    "                            break\n",
    "                        word, pos_tag, chunk_tag, temp_tag = sentence[i]\n",
    "                        m += 1\n",
    "                    global_tag_id += 1\n",
    "                else:\n",
    "                    if i == break_count:\n",
    "                        break\n",
    "                    word, pos_tag, chunk_tag, ner_tag = sentence[i]\n",
    "                    data[j][k][i] = [word, pos_tag, chunk_tag, ner_tag, global_tag_id]\n",
    "                    # print('O', i)\n",
    "                    i += 1\n",
    "                    global_tag_id += 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add tags\n",
    "train_data = id_tags(train_data)\n",
    "val_data = id_tags(val_data)\n",
    "test_data = id_tags(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Pandas and store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data and retain document, sentence, and token IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "normalized_list = []\n",
    "for i, doc in enumerate(train_data):\n",
    "    for j, sentence in enumerate(doc):\n",
    "        for k, example in enumerate(sentence):\n",
    "            temp = [i, j, k] + example\n",
    "            normalized_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Doc_ID', 'Sentence_ID', 'Token_ID', 'Token', 'POS_Tag', 'Chunk_Tag', 'NER_Tag', 'NER_Tag_ID']\n",
    "df = pd.DataFrame(normalized_list, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Sentence_ID</th>\n",
       "      <th>Token_ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>POS_Tag</th>\n",
       "      <th>Chunk_Tag</th>\n",
       "      <th>NER_Tag</th>\n",
       "      <th>NER_Tag_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EU</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rejects</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>German</td>\n",
       "      <td>JJ</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>call</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>boycott</td>\n",
       "      <td>VB</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>British</td>\n",
       "      <td>JJ</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>lamb</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Peter</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Blackburn</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>BRUSSELS</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1996-08-22</td>\n",
       "      <td>CD</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>European</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Commission</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>said</td>\n",
       "      <td>VBD</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>on</td>\n",
       "      <td>IN</td>\n",
       "      <td>I-PP</td>\n",
       "      <td>O</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>it</td>\n",
       "      <td>PRP</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Doc_ID  Sentence_ID  Token_ID       Token POS_Tag Chunk_Tag NER_Tag  \\\n",
       "0        0            0         0          EU     NNP      I-NP   I-ORG   \n",
       "1        0            0         1     rejects     VBZ      I-VP       O   \n",
       "2        0            0         2      German      JJ      I-NP  I-MISC   \n",
       "3        0            0         3        call      NN      I-NP       O   \n",
       "4        0            0         4          to      TO      I-VP       O   \n",
       "5        0            0         5     boycott      VB      I-VP       O   \n",
       "6        0            0         6     British      JJ      I-NP  I-MISC   \n",
       "7        0            0         7        lamb      NN      I-NP       O   \n",
       "8        0            0         8           .       .         O       O   \n",
       "9        0            1         0       Peter     NNP      I-NP   I-PER   \n",
       "10       0            1         1   Blackburn     NNP      I-NP   I-PER   \n",
       "11       0            2         0    BRUSSELS     NNP      I-NP   I-LOC   \n",
       "12       0            2         1  1996-08-22      CD      I-NP       O   \n",
       "13       0            3         0         The      DT      I-NP       O   \n",
       "14       0            3         1    European     NNP      I-NP   I-ORG   \n",
       "15       0            3         2  Commission     NNP      I-NP   I-ORG   \n",
       "16       0            3         3        said     VBD      I-VP       O   \n",
       "17       0            3         4          on      IN      I-PP       O   \n",
       "18       0            3         5    Thursday     NNP      I-NP       O   \n",
       "19       0            3         6          it     PRP      B-NP       O   \n",
       "\n",
       "    NER_Tag_ID  \n",
       "0            0  \n",
       "1            1  \n",
       "2            2  \n",
       "3            3  \n",
       "4            4  \n",
       "5            5  \n",
       "6            6  \n",
       "7            7  \n",
       "8            8  \n",
       "9            9  \n",
       "10           9  \n",
       "11          10  \n",
       "12          11  \n",
       "13          12  \n",
       "14          13  \n",
       "15          13  \n",
       "16          14  \n",
       "17          15  \n",
       "18          16  \n",
       "19          17  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Sentence_ID</th>\n",
       "      <th>Token_ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>POS_Tag</th>\n",
       "      <th>Chunk_Tag</th>\n",
       "      <th>NER_Tag</th>\n",
       "      <th>NER_Tag_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>Israel</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>1746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>MiG-19</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>3109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6355</th>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>County</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>6046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8169</th>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Davis</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>7656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16673</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CNB-120</td>\n",
       "      <td>JJ</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>15603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145768</th>\n",
       "      <td>670</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Super</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>137876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160096</th>\n",
       "      <td>736</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>High</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>151492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162376</th>\n",
       "      <td>744</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>Urdu-speaking</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>153680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169937</th>\n",
       "      <td>781</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>MI-17</td>\n",
       "      <td>JJ</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>160944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195282</th>\n",
       "      <td>904</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>185047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Doc_ID  Sentence_ID  Token_ID          Token POS_Tag Chunk_Tag  \\\n",
       "1819         9           14        19         Israel     NNP      I-NP   \n",
       "3239        15           16        21         MiG-19     NNP      I-NP   \n",
       "6355        36            3         1         County     NNP      I-NP   \n",
       "8169        46            2         1          Davis     NNP      I-NP   \n",
       "16673       82            0         1        CNB-120      JJ      I-NP   \n",
       "...        ...          ...       ...            ...     ...       ...   \n",
       "145768     670            2         4          Super     NNP      I-NP   \n",
       "160096     736            4         6           High     NNP      I-NP   \n",
       "162376     744           13         4  Urdu-speaking     NNP      I-VP   \n",
       "169937     781            3        10          MI-17      JJ      I-NP   \n",
       "195282     904            3        12  Mediterranean     NNP      I-NP   \n",
       "\n",
       "       NER_Tag  NER_Tag_ID  \n",
       "1819     B-LOC        1746  \n",
       "3239    B-MISC        3109  \n",
       "6355    B-MISC        6046  \n",
       "8169    B-MISC        7656  \n",
       "16673   B-MISC       15603  \n",
       "...        ...         ...  \n",
       "145768  B-MISC      137876  \n",
       "160096   B-LOC      151492  \n",
       "162376  B-MISC      153680  \n",
       "169937  B-MISC      160944  \n",
       "195282  B-MISC      185047  \n",
       "\n",
       "[72 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the tags ever start with B?\n",
    "df[df['NER_Tag'].str.startswith('B')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python - Knowledge Graphs",
   "language": "python",
   "name": "knowledge-graphs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
